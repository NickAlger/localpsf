
====================== Begin Newton CG convergence information ======================
Preconditioned inexact Newton-CG with line search
Hp=-g
u <- u + alpha * p
u: parameter, J: cost, g: gradient, H: Hessian, alpha=step size, p=search direction

it=0    : u=u0         -> J -> g -> build precond (optional) -> cgsolve Hp=-g
it=1    : linesearch u -> J -> g -> build precond (optional) -> cgsolve Hp=-g
...
it=last : linesearch u -> J -> g -> Done.

it:      Newton iteration number
nCG:     number of CG iterations in Newton iteration
nJ:      number of cost function evaluations in Newton iteration
nG:      number of gradient evaluations in Newton iteration
nHp:     number of Hessian-vector products in Newton iteration
GN:      True (T) if Gauss-Newton Hessian is used, False (F) if Hessian is used
BP:      True (T) if we built or rebuilt the preconditioner, False (F) otherwise.
cost:    cost, J = Jd + Jr
misfit:  misfit cost, Jd
reg:     regularization cost, Jr
(g,p):   inner product between gradient, g, and Newton search direction, p
||g||L2: l2 norm of gradient
alpha:   step size
tolcg:   relative tolerance for Hp=-g CG solve (unpreconditioned residual decrease)

it nCG nJ nG nHp GN BP         cost  misfit     reg    (g,p) ||g||L2   alpha   tolcg
 0   1  1  1   1  T  F 2.142622e+08 2.1e+08 0.0e+00 -3.1e+08 1.9e+07    ---- 5.0e-01
 1   2  1  1   2  T  F 5.771984e+07 5.3e+07 4.3e+06 -7.5e+07 6.1e+06 1.0e+00 5.0e-01
 2   4  1  1   4  T  F 2.109163e+07 1.8e+07 2.9e+06 -1.4e+07 2.6e+06 1.0e+00 3.6e-01
 3  14  1  1  14  T  F 1.427051e+07 1.1e+07 2.9e+06 -3.1e+06 6.9e+05 1.0e+00 1.9e-01
 4  29  1  1  29  T  F 1.269370e+07 1.0e+07 2.7e+06 -2.1e+05 1.3e+05 1.0e+00 8.2e-02
 5  38  1  1  38  F  F 1.258709e+07 9.9e+06 2.7e+06 -8.6e+02 1.0e+04 1.0e+00 2.3e-02
 6  58  1  1  58  F  F 1.258666e+07 9.9e+06 2.7e+06 -3.6e-01 1.8e+02 1.0e+00 3.1e-03
 7   0  1  1   0  F  F 1.258666e+07 9.9e+06 2.7e+06     ---- 5.5e-01 1.0e+00    ----

converged : True
reason    : Norm of the gradient less than tolerance
cumulative CG iterations : 146
cumulative cost evaluations : 8
cumulative gradient evaluations : 8
cumulative Hessian vector products (excluding preconditioner builds) : 146
======================= End Newton CG convergence information =======================
