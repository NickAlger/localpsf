
====================== Begin Newton CG convergence information ======================
Preconditioned inexact Newton-CG with line search
Hp=-g
u <- u + alpha * p
u: parameter, J: cost, g: gradient, H: Hessian, alpha=step size, p=search direction

it=0    : u=u0         -> J -> g -> build precond (optional) -> cgsolve Hp=-g
it=1    : linesearch u -> J -> g -> build precond (optional) -> cgsolve Hp=-g
...
it=last : linesearch u -> J -> g -> Done.

it:      Newton iteration number
nCG:     number of CG iterations in Newton iteration
nJ:      number of cost function evaluations in Newton iteration
nG:      number of gradient evaluations in Newton iteration
nHp:     number of Hessian-vector products in Newton iteration
GN:      True (T) if Gauss-Newton Hessian is used, False (F) if Hessian is used
BP:      True (T) if we built or rebuilt the preconditioner, False (F) otherwise.
cost:    cost, J = Jd + Jr
misfit:  misfit cost, Jd
reg:     regularization cost, Jr
(g,p):   inner product between gradient, g, and Newton search direction, p
||g||L2: l2 norm of gradient
alpha:   step size
tolcg:   relative tolerance for Hp=-g CG solve (unpreconditioned residual decrease)

it nCG nJ nG nHp GN BP         cost  misfit     reg    (g,p) ||g||L2   alpha   tolcg
 0   3  1  1   3  T  F 2.142622e+08 2.1e+08 0.0e+00 -3.1e+08 1.9e+07    ---- 5.0e-01
 1   8  1  1   8  T  F 6.125953e+07 6.1e+07 2.2e+04 -6.1e+07 8.4e+06 1.0e+00 5.0e-01
 2  16  1  1  16  T  F 3.074817e+07 3.1e+07 1.5e+05 -2.8e+07 4.1e+06 1.0e+00 4.6e-01
 3  34  1  1  34  T  F 1.699042e+07 1.6e+07 9.1e+05 -8.0e+06 1.8e+06 1.0e+00 3.1e-01
 4  52  1  1  52  T  F 1.302612e+07 1.1e+07 2.2e+06 -8.6e+05 5.6e+05 1.0e+00 1.7e-01
 5  79  1  1  79  F  F 1.259948e+07 1.0e+07 2.6e+06 -2.6e+04 9.4e+04 1.0e+00 7.0e-02
 6 102  1  1 102  F  F 1.258671e+07 9.9e+06 2.7e+06 -1.0e+02 6.5e+03 1.0e+00 1.8e-02
 7 151  1  1 151  F  F 1.258666e+07 9.9e+06 2.7e+06 -4.1e-02 1.2e+02 1.0e+00 2.5e-03
 8   0  1  1   0  F  F 1.258666e+07 9.9e+06 2.7e+06     ---- 2.9e-01 1.0e+00    ----

converged : True
reason    : Norm of the gradient less than tolerance
cumulative CG iterations : 445
cumulative cost evaluations : 9
cumulative gradient evaluations : 9
cumulative Hessian vector products (excluding preconditioner builds) : 445
======================= End Newton CG convergence information =======================
